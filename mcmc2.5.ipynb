{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC2.5: Dense and Sparse Matrices\n",
    "\n",
    "This section is not necessarily for Marcov chain Monte Carlo itself, but the use of Sparse matrices is important to speed up quantum Monte Carlo simulations.\n",
    "\n",
    "## Dense matrix\n",
    "\n",
    "To use dense matrices, LinearAlgebra provides wrapper to BLAS/LAPACK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recommend Intel MKL instead of OpenBLAS. You can check whether MKL is used by the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":mkl"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLAS.vendor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D Array is called Vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Array{Int64, 1} == Vector{Int64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D Array is called Matrix, which I later call dense matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Array{Float64, 2} == Matrix{Float64}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix and Array of Array are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = [1 2\n",
    "                 3 4]\n",
    "array =[[1, 2], [3, 4]]\n",
    "matrix == array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia's support on 3-rank tensors is limited, but still we can define and use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2×2 Array{Float64,3}:\n",
       "[:, :, 1] =\n",
       " 0.0  0.0\n",
       " 0.0  0.0\n",
       "\n",
       "[:, :, 2] =\n",
       " 0.0  0.0\n",
       " 0.0  0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = zeros(Float64, 2, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful, matrices are stored columnwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000023 seconds (7 allocations: 78.375 KiB)\n",
      "  0.000395 seconds (7 allocations: 78.375 KiB)\n",
      "End!\n"
     ]
    }
   ],
   "source": [
    "mat = ones(10000, 10000)\n",
    "mat[:, 1]\n",
    "mat[1, :]\n",
    "@time mat[:, 1]\n",
    "@time mat[1, :]\n",
    "println(\"End!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, vertical vectors are more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 17.0\n",
       " 39.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1.0 2.0; 3.0 4.0] * [5.0; 6.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLAS/LAPACK\n",
    "\n",
    "Dense matrices are not memory-efficient, but support BLAS/LAPACK. The most important BLAS operation in quantum Monte Carlo is rank-1 update (or other finite-rank updates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×1000 Array{Float64,2}:\n",
       " 0.0309637  0.963237   0.659809  0.161889  …  0.554004  0.24017    0.701533 \n",
       " 0.252961   0.256455   0.887348  0.720892     0.137021  0.62597    0.516955 \n",
       " 0.801891   0.0355228  0.659865  0.146784     0.910977  0.957655   0.226707 \n",
       " 0.302365   0.489994   0.748127  0.362462     0.202818  0.695144   0.524791 \n",
       " 0.589881   0.720213   0.731793  0.327218     0.316837  0.824122   0.338946 \n",
       " 0.842267   0.509839   0.580669  0.392607  …  0.280414  0.607666   0.307534 \n",
       " 0.838772   0.4507     0.245435  0.641608     0.358249  0.907074   0.31072  \n",
       " 0.666076   0.886652   0.607456  0.702718     0.702585  0.300749   0.108952 \n",
       " 0.145292   0.694542   0.603646  0.832036     0.33536   0.365673   0.766862 \n",
       " 0.106796   0.217884   0.750812  0.134405     0.296914  0.294457   0.533726 \n",
       " 0.0309095  0.778457   0.622044  0.682674  …  0.679265  0.937097   0.186918 \n",
       " 0.0482619  0.757842   0.958546  0.866743     0.446877  0.0501466  0.808526 \n",
       " 0.0540594  0.45534    0.566973  0.176375     0.384151  0.806999   0.565118 \n",
       " ⋮                                         ⋱                                \n",
       " 0.847315   0.786372   0.927031  0.199818     0.765644  0.322786   0.370176 \n",
       " 0.335099   0.477852   0.747502  0.459441     0.344902  0.417643   0.307009 \n",
       " 0.264117   0.718749   0.818631  0.19641   …  0.101443  0.0414701  0.228113 \n",
       " 0.470633   0.0569275  0.351427  0.814759     0.481787  0.957067   0.91941  \n",
       " 0.796075   0.411884   0.62141   0.961295     0.136001  0.197934   0.89405  \n",
       " 0.813308   0.834304   0.392224  0.67464      0.586143  0.884327   0.48682  \n",
       " 0.44808    0.0387928  0.102844  0.545006     0.429104  0.999181   0.0104041\n",
       " 0.907464   0.471891   0.292026  0.310835  …  0.552723  0.728102   0.87067  \n",
       " 0.208373   0.219395   0.218514  0.405831     0.749801  0.71102    0.639799 \n",
       " 0.785347   0.535684   0.989867  0.163825     0.469519  0.32527    0.565647 \n",
       " 0.488304   0.142508   0.694969  0.810794     0.433986  0.955496   0.674934 \n",
       " 0.119809   0.251597   0.387733  0.931091     0.516472  0.986776   0.410248 "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(Float64, 1000, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the Sherman-Morrison formula!\n",
    "$$\\left( A+\\vec{u} \\vec{v}^T \\right)^{-1} = A^{-1} - \\frac{A^{-1} \\vec{u} \\vec{v}^TA^{-1}}{1 + \\vec{v}^T A^{-1} \\vec{u}}$$\n",
    "Of course, the vectors are vertical. I define $B = A+\\vec{u} \\vec{v}^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse matrix\n",
    "\n",
    "If your program is intensively using sparse matrices, you should use python instead because Julia only supports CSC matrix. Julia's native support for sparse matrices is not strong, so I do not recommend to write a code using multiple types of sparse matrices in Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative solvers\n",
    "\n",
    "~ under construction ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
